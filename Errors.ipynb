{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as any collaborators you worked with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c0e6f80c9a8d85d80baddc8df3890a0",
     "grade": false,
     "grade_id": "cell-7531378247537850",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the factorial function from scipy\n",
    "from scipy.special import factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57fe3d1a770d32fc71d10c52d47d5765",
     "grade": false,
     "grade_id": "cell-1055125360070174",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# HW 1:  Forms of Error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "763bdcd61a173c57e8d82dcd9519ee2c",
     "grade": false,
     "grade_id": "cell-9681214437904696",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1:  definition of errors\n",
    "\n",
    "**(a)**  [4 pts] Write a short python program to calculate and return, the absolute error, relative error and degree of decimal precision (as defined in class) given an object `f` and its approximation `F`.  Note, both `f` and `F` can be numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c9bcb87e713e8ee4fb90ec822ed4d9f",
     "grade": false,
     "grade_id": "cell-a6ede65cf8ed685f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def errors(f,F):\n",
    "    \"\"\" calculate various measures of error of an object f and its approximation F\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f:  numpy.array (or float)\n",
    "        array of true values\n",
    "        \n",
    "    F: numpy.array\n",
    "        array of approximate values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    e: array of absolute errors\n",
    "    r: array of relative errors\n",
    "    p: integer array of precisions\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    try:\n",
    "#         import pdb; pdb.set_trace()\n",
    "        if type(f) in (numpy.ndarray, list) and type(F) in (numpy.ndarray, list):\n",
    "            if len(f) == len(F):\n",
    "                abs_err = []\n",
    "                relative_err = []\n",
    "                precision = []\n",
    "                for i in range(len(f)):\n",
    "                    abs_err.append(numpy.abs(f[i] - F[i]))\n",
    "                    relative_err.append(abs_err[i]/numpy.abs(f[i]))\n",
    "                    precision.append(int(-numpy.log10(relative_err[i]/5.)))\n",
    "                return abs_err, relative_err, precision\n",
    "            else:\n",
    "                print(\"Parameter Error: Size of f and F should be equal\")\n",
    "                \n",
    "        elif type(f) in (float, numpy.float64, int) and type(F) in (float, numpy.float64, int):\n",
    "            abs_err = numpy.abs(f - F)\n",
    "            relative_err = (abs_err/numpy.abs(f))\n",
    "            precision = (int(-numpy.log10(relative_err/5.)))\n",
    "            return abs_err, relative_err, precision\n",
    "        else:\n",
    "            print(\"Parameter Error: Type of f and F should be equal\")  \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Error Occurred: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0]\n",
      "[ 2.71828183  7.3890561  20.08553692]\n",
      "True\n",
      "passed array test\n"
     ]
    }
   ],
   "source": [
    "e,r,p = errors(numpy.exp(1),2.72)\n",
    "answer = [0.0017181715409551046, 0.0006320799863232398, 3]\n",
    "numpy.testing.assert_allclose([e,r,p], answer)\n",
    "\n",
    "# test with array input\n",
    "x = [1., 2., 3.]\n",
    "f = numpy.exp(x)\n",
    "F = [ 2.718,  7.389,  20.085]\n",
    "print(x)\n",
    "print(f)\n",
    "print(len(F) == len(f))\n",
    "e,r,p = errors(f,F)\n",
    "numpy.testing.assert_allclose(e,[2.81828459e-04, 5.60989307e-05, 5.36923188e-04])\n",
    "numpy.testing.assert_allclose(r,[1.03678896e-04, 7.59216467e-06, 2.67318315e-05])\n",
    "numpy.testing.assert_allclose(p,[4, 5, 5])\n",
    "print('passed array test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "811e12c9907b5b3fc93463b352dff5c3",
     "grade": true,
     "grade_id": "cell-da2659b413c73ca7",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed scalar test\n",
      "passed array test\n"
     ]
    }
   ],
   "source": [
    "# test simple scalars\n",
    "e,r,p = errors(numpy.exp(1),2.72)\n",
    "answer = [0.0017181715409551046, 0.0006320799863232398, 3]\n",
    "numpy.testing.assert_allclose([e,r,p], answer)\n",
    "print('passed scalar test')\n",
    "\n",
    "# test with array input\n",
    "x = [1., 2., 3.]\n",
    "f = numpy.exp(x)\n",
    "F = [ 2.718,  7.389,  20.085]\n",
    "e,r,p = errors(f,F)\n",
    "numpy.testing.assert_allclose(e,[2.81828459e-04, 5.60989307e-05, 5.36923188e-04])\n",
    "numpy.testing.assert_allclose(r,[1.03678896e-04, 7.59216467e-06, 2.67318315e-05])\n",
    "numpy.testing.assert_allclose(p,[4, 5, 5])\n",
    "print('passed array test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90b05b8f5232214b804110a26a04be3f",
     "grade": false,
     "grade_id": "cell-bef4e3baf992ed93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(b)** [4 pts] Use your routine to calculate various errors for several rational approximations to $\\pi$\n",
    "\n",
    "* $f = \\pi$ and $F = 22 / 7$\n",
    "* $f = \\pi$ and $F = 314 / 100$\n",
    "* $f = \\pi$ and $F = 355 / 113$\n",
    "\n",
    "Compare the most precise approximation to the least precise approximation.  How many more digits of precision do you gain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error for pi (22/7):  0.0012644892673496777\n",
      "Relative Error for pi (22/7):  0.0004024994347707008\n",
      "Precision for pi (22/7):  4\n",
      "Absolute Error for pi (314/100):  0.0015926535897929917\n",
      "Relative Error for pi (314/100):  0.0005069573828972128\n",
      "Precision for pi (314/100):  3\n",
      "Absolute Error for pi (355/113):  2.667641894049666e-07\n",
      "Relative Error for pi (355/113):  8.49136787674061e-08\n",
      "Precision for pi (355/113):  7\n"
     ]
    }
   ],
   "source": [
    "# you can put some working code here to generate your answers, but put your answers in the cell below\n",
    "import math\n",
    "# Check for f equals pi and F = 22/7\n",
    "f = math.pi\n",
    "F = 22/7\n",
    "e,r,p = errors(f,F)\n",
    "print(\"Absolute Error for pi (22/7): \", e)\n",
    "print(\"Relative Error for pi (22/7): \", r)\n",
    "print(\"Precision for pi (22/7): \", p)\n",
    "\n",
    "# Check for f equals pi and F = 314/100\n",
    "f = math.pi\n",
    "F = 314/100\n",
    "e,r,p = errors(f,F)\n",
    "print(\"Absolute Error for pi (314/100): \", e)\n",
    "print(\"Relative Error for pi (314/100): \", r)\n",
    "print(\"Precision for pi (314/100): \", p)\n",
    "\n",
    "# Check for f equals pi and F = 355/113\n",
    "f = math.pi\n",
    "F = 355/113\n",
    "e,r,p = errors(f,F)\n",
    "print(\"Absolute Error for pi (355/113): \", e)\n",
    "print(\"Relative Error for pi (355/113): \", r)\n",
    "print(\"Precision for pi (355/113): \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9ac9462caae1146fa324fe338dd0c1d",
     "grade": true,
     "grade_id": "cell-4300360216304258",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$e = Absolute \\ error$ and $r = Relative \\ error$ and $p = Precision$\n",
    "* $f = \\pi$ and $F = 22 / 7$ and $e = 0.0012644892673496777$ and $r = 0.0004024994347707008$ and $p=4$\n",
    "* $f = \\pi$ and $F = 314 / 100$ and $e = 0.0015926535897929917$ and $r = 0.0005069573828972128$ and $p=3$\n",
    "* $f = \\pi$ and $F = 355 / 113$ and $e = 2.667641894049666e-07$ and $r = 8.49136787674061e-08$ and $p=7$\n",
    "* $The \\ precision \\ of \\ the \\ most \\ precised \\ approximation \\ is \\ 7$\n",
    "* $The \\ precison \\ of \\ the \\ least \\ precised \\ approximation \\ is \\ 3$\n",
    "* $ The \\ most \\ precise \\ approximation \\ among \\ the \\ three\\ gained \\ 4 \\ more \\ digits \\ of \\ precision$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9680d17c5d494ccba620eb525f2ae882",
     "grade": false,
     "grade_id": "cell-23707a8e710ca676",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(c)** [4 pts] $F = n \\log(n) - n$ is Stirling's approximation to  $f = \\log(n!)$ for large values of $n$. \n",
    "Do the following\n",
    "\n",
    "* Make a plot showing the relative error and degree of decimal precision for $f$ and $F$ as a function of integer $n$\n",
    "\n",
    "* Estimate the smallest value of $n$ where Stirling's approximation is good to 4 decimal places of precision.  \n",
    "\n",
    "**Note**: If you use the `factorial` function imported from `scipy.special`, you will not be able to answer this question.  **Why?**  \n",
    "\n",
    "**Hint**: However there is another way to evaluate $\\log(n!)$ for integer $n$ that will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6195fab472e4537966b7eba4a529a13b",
     "grade": true,
     "grade_id": "cell-a5639245c28a1642",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least N:  [1450]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import math\n",
    "# n = 10**100000\n",
    "# N = 1453\n",
    "n = numpy.linspace(2, 1453, 1451)\n",
    "# F_n = n*math.log(n) - n\n",
    "f = []\n",
    "F = []\n",
    "N = 1453\n",
    "N\n",
    "f_v = 0\n",
    "for i in range(2, N):\n",
    "    F.append(i*math.log(i) - i)\n",
    "    for j in range(i, i+1):\n",
    "        f_v += math.log(j)\n",
    "    f.append(f_v)\n",
    "e,r,p = errors(f,F)\n",
    "arr = numpy.array(p)\n",
    "bool_arr = arr == 4\n",
    "output = numpy.where(bool_arr)[0]\n",
    "print('least N: ',output)\n",
    "plt.plot(n,numpy.array(r),'r',label='Relative Error')\n",
    "plt.plot(n,numpy.array(p),'g',label='precision')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('n')\n",
    "# plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab8966bfa41224e3345e4cd4fcbf9749",
     "grade": true,
     "grade_id": "cell-dcc45d9028355b73",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$F = n \\log(n) - n$ is Stirling's approximation to  $f = \\log(n!)$\n",
    "* n = 1450 is the smallest value of $n$ where Stirling's approximation is good to 4 decimal places of precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27bfc8b15912bb6e1cdfa2dfd103ced4",
     "grade": false,
     "grade_id": "cell-6968179660613369",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "[4 pts] Given the Taylor polynomial expansions of two functions around $x=0$\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} = 1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + O(\\Delta x^4)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\cosh \\Delta x = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^6)$$\n",
    "\n",
    "calculate their sum and product as well as the order of approximation for the truncation error (i.e. determine the exponent that belongs in the $O$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77d458abae3cfa5157eca11bd346e444",
     "grade": true,
     "grade_id": "cell-8500724062567566",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} = 1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + O(\\Delta x^4)$$\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} = p(\\Delta x)  + O(\\Delta x^4) $$\n",
    "\n",
    "and\n",
    "$$\\cosh \\Delta x = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^4)$$\n",
    "\n",
    "$$\\cosh \\Delta x = q(\\Delta x) + O(\\Delta x^4)$$\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} + \\cosh \\Delta x = (1 + \\Delta x + \\Delta x^2 + \\Delta x^3) + (1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!}) + O(\\Delta x^4)$$\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} + \\cosh \\Delta x = 2 + \\Delta x + 3/2\\Delta x^2 + \\Delta x^3 + O(\\Delta x^4)$$\n",
    "\n",
    "\n",
    "$$(\\frac{1}{1-\\Delta x})\\cosh \\Delta x = (1 + \\Delta x + \\Delta x^2 + \\Delta x^3)(1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!}) + O(\\Delta x^{4})$$\n",
    "\n",
    "\n",
    "$$(\\frac{1}{1-\\Delta x})\\cosh \\Delta x = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + \\Delta x + \\frac{\\Delta x^3}{2!} + \\frac{\\Delta x^5}{4!} + \\Delta x^2 + \\frac{\\Delta x^4}{2!} + \\frac{\\Delta x^6}{4!} + \\Delta x^3 + \\frac{\\Delta x^5}{2!} + \\frac{\\Delta x^7}{4!}  + O(\\Delta x^{4})\n",
    "$$\n",
    "$$(\\frac{1}{1-\\Delta x})\\cosh \\Delta x = 1 + \\Delta x + 3/2\\Delta x^2 + 3/2\\Delta x^3 + + O(\\Delta x^{4})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "237fcd7151c710b1c2fe86744794671b",
     "grade": false,
     "grade_id": "cell-5632471080286207",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 3:  The great Exp challenge...\n",
    "\n",
    "Here you will attempt to write a function to calculate $e^x$ using its Taylor polynomial approximation expanded around $x_0=0$\n",
    "\n",
    "$$e^x \\approx T_n(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots + \\frac{x^n}{n!}$$\n",
    "\n",
    "such that the relative error of $f=e^x$ and $F=T_n(x)$ is of order Machine epsilon ($\\epsilon_{machine}$) for  $x\\in[-50,50]$.  This problem is actually a bit of a stinker and takes a bit of thought (particularly for $x<0$).  But I'll work you through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d16eac32cec2913a95095d153a7994b7",
     "grade": false,
     "grade_id": "cell-8186992197557199",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** [4 pts] Assume $x> 0$ and show that the upper bound on the *relative error*  at term $n$ \n",
    "\n",
    "$$r_n = \\frac{|e^x - T_n(x)|}{|e^x|}$$\n",
    "\n",
    "is given by\n",
    "\n",
    "$$r_n \\leq \\left | \\frac{x^{n+1}}{(n + 1)!} \\right |$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c066945aa96e6e08fcb676cf3b3e08f3",
     "grade": true,
     "grade_id": "cell-2747685663052674",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$$e^x \\approx T_n(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots + \\frac{x^n}{n!}$$\n",
    "\n",
    "$$\n",
    "    R_N(x) = \\frac{f^{(N+1)}(c) \\cdot (x - x_0)^{N+1}}{(N+1)!}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f=e^x \\ and \\  \\ F=T_n(x) \\  \\ f^{(N+1)}(c) = e^c  \\ \\ x_0 = 0\n",
    "$$\n",
    "\n",
    "$$ f - F = e^x - T_n(x) = R_N(x)$$\n",
    "\n",
    "$$ r_n = \\frac{|f - F|}{|f|}$$\n",
    "\n",
    "$$ r_n = \\frac{|e^x - T_n(x)|}{|e^x|}$$\n",
    "\n",
    "$$ r_n \\leq \\left | \\frac{R_n(x)|}{|e^x|} | \\right | $$\n",
    "\n",
    "$$ r_n \\leq \\left | \\frac{f^{(n+1)}(c) \\cdot (x - x_0)^{n+1}}{e^c \\cdot (n+1)!}  \\right | $$\n",
    "\n",
    "$$ r_n \\leq \\left | \\frac{e^c \\cdot x ^{n+1}}{e^c \\cdot (n+1)!} \\right | $$\n",
    "\n",
    "$$r_n \\leq \\left|\\frac{x^{n+1}}{(n+1)!} \\right |$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a252bb988e5ae52a24a2e87dfe820b2",
     "grade": false,
     "grade_id": "cell-4678254376542691",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** [4 pts] Analytically show that for **large** $x\\gg1$ and $n$, $r_n \\leq \\epsilon_{\\text{machine}}$ implies that we need *approximately* $n > e \\cdot x$ terms in the series (where $e = \\text{exp}(1)$).\n",
    "\n",
    "*Hint* Use Stirling's approximation $log (n!) \\approx n~log~n - n$ (and then this problem is still a bit tricky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8152aede9f1e1f429a231ee2b82df69c",
     "grade": true,
     "grade_id": "cell-4305745011657702",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "$$r_n \\leq \\left|\\frac{x^{n+1}}{(n+1)!} \\right|$$\n",
    "$$r_n \\leq \\epsilon_{\\text{machine}}$$\n",
    "\n",
    "$$(n+1)~log~x - log(n + 1)! \\leq log(\\epsilon_{\\text{machine}}) $$\n",
    "$$(n+1)~log~x - ((n+1)~log(n + 1) - (n+1)) \\leq log(\\epsilon_{\\text{machine}}) $$\n",
    "$$(n+1)~log~x - (n+1)~log(n + 1) + (n+1)) \\leq log(\\epsilon_{\\text{machine}})$$\n",
    "$$(n+1)(log~x - log(n + 1) + 1) \\leq log(\\epsilon_{\\text{machine}})$$\n",
    "$$(n+1)(log(\\frac{xe}{(n + 1)}) \\leq log(\\epsilon_{\\text{machine}})$$\n",
    "$$\\frac{(xe)^{n+1}}{(n+1)^{n+1}} \\leq \\epsilon_{\\text{machine}}$$\n",
    "$$\\frac{xe}{(n + 1)} < 1$$\n",
    "$$n+1 > xe$$\n",
    "$$n > xe$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9cef1843dc0ae1deb7e6dbe5f77c33c",
     "grade": false,
     "grade_id": "cell-8048500717179941",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** [6 pts] Use this result to write a Python function that accurately approximates $e^x$ using $T_n(x)$ for scalar $x$ and returns both the estimate and the number of terms in the series.  Note that the testing tolerance will be $8 \\cdot \\epsilon_{\\text{machine}}$ over the range $x\\in[-50,50]$\n",
    "\n",
    "Make sure to document your code including expected inputs, outputs, and assumptions being made.\n",
    "\n",
    "Some Hints:\n",
    "* To make your life easier,  we will assume $x$ and $T_n(x)$ are just of type float (not arrays)\n",
    "* Think about how we evaluated polynomials efficiently in class\n",
    "* $T_n(x)$ for $x<0$ is a highly unstable alternating series with severe cancellation issues. However, there is a simple fix that will return accurate solutions independent of the sign of $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80286c759520479af4ce906ac70f62e5",
     "grade": false,
     "grade_id": "cell-5914967225034965",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "\n",
    "\n",
    "def Tn_exp(x):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Function to calculate e^x using Taylor series approximation about x0 = 0\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "#     assert(isinstance(x,float))\n",
    "    \n",
    "    inv = False\n",
    "    if x<0:\n",
    "        x = abs(x)\n",
    "        inv = True\n",
    "        \n",
    "    MAX_N = int(numpy.ceil(3*x))+50\n",
    "    \n",
    "    p = []\n",
    "    for n in range(MAX_N + 1):\n",
    "        p.append(1 / factorial(n))    \n",
    "    p.reverse()    \n",
    "    \n",
    "    Tn = p[0]\n",
    "    for coefficient in p[1:]:\n",
    "        Tn = Tn * x + coefficient\n",
    "        \n",
    "    if inv:\n",
    "        Tn = 1/Tn\n",
    "\n",
    "                        \n",
    "    \n",
    "    return Tn, MAX_N\n",
    "\n",
    "def Tn_exp1(x):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "    eps = numpy.finfo(float).eps\n",
    "    tolerance = 8 * eps\n",
    "    f = numpy.exp(x)\n",
    "    Tn = 0\n",
    "    MAX_N = 0\n",
    "    rel_err = 0\n",
    "    cond = True\n",
    "    denom = 1\n",
    "    nume = 0\n",
    "    while cond:\n",
    "        denom = 1/math.factorial(MAX_N)\n",
    "        Tn += (x**MAX_N) * denom\n",
    "        rel_err = numpy.abs(f - Tn)/numpy.abs(f)\n",
    "        if rel_err < tolerance:\n",
    "            cond = False\n",
    "        MAX_N+= 1\n",
    "\n",
    "    \n",
    "    return Tn, MAX_N\n",
    "\n",
    "def Tn_exp2(x):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "    eps = numpy.finfo(float).eps\n",
    "    tolerance = 8 * eps\n",
    "    f = numpy.exp(x)\n",
    "    Tn = 0\n",
    "    MAX_N = int(numpy.ceil(3*x))+100\n",
    "    rel_err = 0\n",
    "    cond = True\n",
    "    denom = 1\n",
    "    nume = 0\n",
    "    i = 0\n",
    "    summ = 1\n",
    "    N = 0\n",
    "    for i in range(MAX_N):\n",
    "        Tn += 1\n",
    "        Tn *= abs(x)/(MAX_N - i)\n",
    "        rel_err = numpy.abs(f - Tn)/numpy.abs(f)\n",
    "#         if rel_err < tolerance:\n",
    "#             N = i\n",
    "#             break\n",
    "    if x < 0:\n",
    "        Tn = 1/Tn\n",
    "    return Tn, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 4.252190255480811 eps_machine\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# # Feel free to test your code here and/or make a plot of errors\n",
    "\n",
    "x = numpy.linspace(1, 2, 2)\n",
    "eps = numpy.finfo(float).eps\n",
    "tolerance = 8 * eps\n",
    "\n",
    "x = numpy.linspace(-50, 50, 101)\n",
    "eps = numpy.finfo(float).eps\n",
    "tolerance = 8 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab0f32ce185cc2c7955fb0d04d65f027",
     "grade": true,
     "grade_id": "cell-9688375319882602",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 4.252190255480811 eps_machine\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Testing Cell (do not copy)\n",
    "\n",
    "x = numpy.linspace(-50, 50, 101)\n",
    "eps = numpy.finfo(float).eps\n",
    "tolerance = 8 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b1d4a353e51fbba1658f5a6968d1b42",
     "grade": false,
     "grade_id": "cell-c154452f653c5adc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(d)** [4 pts] In ieee double precision,  the largest value of $x$ that has $e^x<$ `numpy.finfo(float).max` is about 709 (i.e. `numpy.log(numpy.finfo(float).max))`. \n",
    "\n",
    "* What is the relative error in units of machine epsilon for your routine and `f=numpy.exp(709)`\n",
    "* What is the relative error in units of machine epsilon for `F=numpy.exp(1)**709` and `f=numpy.exp(709)`\n",
    "\n",
    "Explain your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tn:  8.21840746155497e+307\n",
      "f:  8.218407461554972e+307\n",
      "Relative error:  2.428500069960141e-16\n",
      "Epsilon:  2.220446049250313e-16\n",
      "Relative error in units of machine epsilon 1.0936992010141715\n"
     ]
    }
   ],
   "source": [
    "f = numpy.exp(709)\n",
    "Tn, N = Tn_exp2(709)\n",
    "eps = numpy.finfo(float).eps\n",
    "e, r, _ = errors(f, Tn)\n",
    "rel_err_ep = r/eps\n",
    "print('Tn: ', Tn)\n",
    "print('f: ', f)\n",
    "print('Relative error: ', r)\n",
    "print('Epsilon: ', eps)\n",
    "print('Relative error in units of machine epsilon', rel_err_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5a47ab9f08e7fe4764609703387ef9d",
     "grade": true,
     "grade_id": "cell-26e754d164cf2a3a",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "* f = numpy.exp(709)\n",
    "* f = 8.218407461554972e+307\n",
    "* Tn = 8.218407461554959e+307\n",
    "* eps = 2.220446049250313e-16\n",
    "* r = $\\frac{e}{|f|} = \\frac{|f - F|}{|f|} $\n",
    "\n",
    "* r = 1.578525045474092e-15\n",
    "* r_ep = $ \\frac{r}{eps} $\n",
    "* r_ep = 1.0936992010141715\n",
    "* Relative error in units of machine epsilon 1.0936992010141715\n",
    "* Since my function is written around the assumption that the relative error should be less than 8 times the epsilon machine value. Hence least relative error is around 1.0936992010141715 times epsilon machine value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ddafb7ce96253940253bdd63de4c5a3",
     "grade": false,
     "grade_id": "cell-aaa3ac7c64bd5868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(e)**  **How low can you go?** [4 pts] Can you modify your routine for `Tn_exp(x)`) to approximate $e^x$ on the range $x\\in[-709, 709]$ to within 20 $\\epsilon_{machine}$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c184e65af5b8e5f46c673245638f9ef",
     "grade": false,
     "grade_id": "cell-28a21d2a7d0bda99",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def Tn_exp(x, tolerance=tolerance):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Function to calculate e^x using Taylor series approximation about x0 = 0\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "#     assert(isinstance(x,float))\n",
    "    inv = False\n",
    "    if x<0:\n",
    "        x = abs(x)\n",
    "        inv = True\n",
    "        \n",
    "    MAX_N = int(numpy.ceil(3*x))+50\n",
    "    \n",
    "    p = []\n",
    "    for n in range(MAX_N + 1):\n",
    "        p.append(1 / factorial(n))    \n",
    "    p.reverse()    \n",
    "    \n",
    "    Tn = p[0]\n",
    "    for coefficient in p[1:]:\n",
    "        Tn = Tn * x + coefficient\n",
    "        \n",
    "    if inv:\n",
    "        Tn = 1/Tn\n",
    "                         \n",
    "    return Tn, MAX_N\n",
    "\n",
    "def Tn_exp1(x, tolerance=8*numpy.finfo(float).eps):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "    inv = False\n",
    "    if x < 0:\n",
    "        inv = True\n",
    "        x = abs(x)\n",
    "    eps = numpy.finfo(float).eps\n",
    "#     tolerance = 8 * eps\n",
    "    f = numpy.exp(x)\n",
    "    Tn = 1.0\n",
    "    Tn_li = []\n",
    "    MAX_N = int(numpy.ceil(3*x))\n",
    "    rel_err = 0\n",
    "    cond = True\n",
    "    Upperbound = 1\n",
    "\n",
    "    \n",
    "    for i in range(MAX_N, 0, -1):\n",
    "         Tn_li.append((Tn/i)*(x) + 1)\n",
    "    if inv and sum(Tn_li) !=0:\n",
    "        Tn = 1/sum(Tn_li)\n",
    "    else:\n",
    "        Tn = sum(Tn_li)\n",
    "    return Tn, MAX_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 5.017239282570816e+145 eps_machine\n",
      "[1.11405091e+130 2.38443646e+125 5.47630349e+120 1.35361552e+116\n",
      " 3.61224130e+111 1.04421296e+107 3.28161281e+102 1.12546823e+098\n",
      " 4.22965688e+093 1.74948075e+089 8.00187521e+084 4.06774556e+080\n",
      " 2.31082079e+076 1.47566758e+072 1.06607684e+068 8.77335906e+063\n",
      " 8.28664561e+059 9.05677989e+055 1.15563680e+052 1.73842371e+048\n",
      " 3.11617235e+044 6.73486063e+040 1.77793219e+037 5.81596908e+033\n",
      " 2.39541365e+030 1.26449043e+027 8.72707702e+023 8.05275459e+020\n",
      " 1.01878580e+018 1.81830643e+015 4.72896784e+012 1.85959854e+010\n",
      " 1.15331722e+008 1.18381049e+006 2.12405522e+004 7.07205770e+002\n",
      " 4.58033324e+001 5.50009435e+000 9.39902145e-001 1.40709871e-001\n",
      " 9.51186003e-003 1.45962756e-004 2.91192073e-007 4.12919442e-011\n",
      " 7.44021132e-016 0.00000000e+000 3.94633174e-016 5.74814541e-016\n",
      " 2.09315751e-016 1.52442503e-016 0.00000000e+000 1.61712796e-016\n",
      " 1.17773761e-016 6.86187326e-016 3.74807364e-016 0.00000000e+000\n",
      " 2.65066700e-016 4.12918200e-011 2.91191987e-007 1.45941454e-004\n",
      " 9.42223703e-003 1.23352900e-001 4.84510081e-001 8.46156079e-001\n",
      " 9.78634000e-001 9.98587981e-001 9.99952922e-001 9.99999155e-001\n",
      " 9.99999991e-001 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 1.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000]\n",
      "[1.35555571e-178 4.17728241e-177 1.38131060e-175 4.91580804e-174\n",
      " 1.88873965e-172 7.86104308e-171 3.55692075e-169 1.75636933e-167\n",
      " 9.50349818e-166 5.65956796e-164 3.72701927e-162 2.72784317e-160\n",
      " 2.23114418e-158 2.05137785e-156 2.13373944e-154 2.52821809e-152\n",
      " 3.43813678e-150 5.41020786e-148 9.93933329e-146 2.15271870e-143\n",
      " 5.55582896e-141 1.72882791e-138 6.57103980e-136 3.09482964e-133\n",
      " 1.83523183e-130 1.39483139e-127 1.38602393e-124 1.84137455e-121\n",
      " 3.35410232e-118 8.61898753e-115 3.22738884e-111 1.82725804e-107\n",
      " 1.63164329e-103 2.41131941e-099 6.22951442e-095 2.99035783e-090\n",
      " 2.84535349e-085 5.68951002e-080 2.44472933e-074 2.06976916e-068\n",
      " 2.63726573e-062 3.76185114e-056 5.41544438e-050 7.79703936e-044\n",
      " 1.12260114e-037 1.61629725e-031 2.32711040e-025 3.35052405e-019\n",
      " 4.82401326e-013 6.94551169e-007 1.00000000e+000 1.43977873e+006\n",
      " 2.07296279e+012 2.98460773e+018 4.29717473e+024 6.18698078e+030\n",
      " 8.90788333e+036 1.28253809e+043 1.84657053e+049 2.65826574e+055\n",
      " 3.79180599e+061 4.83145666e+067 4.09043238e+073 1.75762060e+079\n",
      " 3.51450181e+084 3.34408140e+089 1.60526156e+094 4.14710717e+098\n",
      " 6.12879056e+102 5.47268081e+106 3.09848007e+110 1.16022908e+114\n",
      " 2.98142365e+117 5.43072565e+120 7.21488266e+123 7.16932533e+126\n",
      " 5.44890289e+129 3.23119563e+132 1.52182916e+135 5.78426572e+137\n",
      " 1.79991142e+140 4.64528878e+142 1.00610370e+145 1.84835782e+147\n",
      " 2.90855211e+149 3.95535497e+151 4.68660784e+153 4.87477235e+155\n",
      " 4.48200528e+157 3.66589990e+159 2.68310928e+161 1.76691933e+163\n",
      " 1.05224411e+165 5.69356331e+166 2.81142052e+168 1.27209581e+170\n",
      " 5.29453596e+171 2.03425356e+173 7.23950137e+174 2.39390087e+176\n",
      " 7.37704835e+177]\n",
      "<function Tn_exp at 0x7f3a5804c940>\n"
     ]
    }
   ],
   "source": [
    "x = numpy.linspace(-709, 709, 101)\n",
    "tolerance = 20 * eps\n",
    "Tn_exp(-709, tolerance=tolerance)\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi, tolerance=tolerance)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "\n",
    "print(r)\n",
    "print(answer)\n",
    "print(Tn_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6011675fe1441e14f574073b0e66e871",
     "grade": true,
     "grade_id": "cell-96883753198883843",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 5.017239282570816e+145 eps_machine\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e5744f4c9dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maxmimum relative error = {} eps_machine'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m  \u001b[0;34m<\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Success!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = numpy.linspace(-709, 709, 101)\n",
    "tolerance = 20 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi, tolerance=tolerance)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a18929a8d1127d2e6e77c98b23fb7855",
     "grade": false,
     "grade_id": "cell-6605000347660435",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "Consider a computing system that uses deoxyribonucleic acid (DNA) to store information.  Given that DNA is formed from the 4 nucleobases adenine, cytosine, guanine, and thymine (uracil is only found in RNA) let us assume that our storage of numbers will be base 4.  Answer the following questions based on this assuming that we have $p=3$ for the mantissa and the exponent $E \\in [-3, 3]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47f4d67565808d7f75e55f0689f21dd6",
     "grade": false,
     "grade_id": "cell-9339658002746268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** [4 pts] Calculate how many numbers can we represent with this system?  What are the underflow and overflow limits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0255974fb370e1c331638d41f074ddf",
     "grade": true,
     "grade_id": "cell-623b625975f5da41",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "$$f=\\pm d_1 . d_2 .d_3\\times 2^E ~~~~ \\text{with} ~~~~ E \\in [-3, 3]$$\n",
    "$$ 2 \\times 3 \\times 4 \\times 4  \\times 7 + 1 = 673$$\n",
    "* Smallest number that can be represented is the underflow:  $1.0_4 \\times 4^{-3} = 0.01562$\n",
    "* Largest number that can be represented is the overflow:  $3.33_4 \\times 4^3 = 252$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29c7fc5ca0808f62a6b35897f3fbbe87",
     "grade": false,
     "grade_id": "cell-9339658dsfsdf46268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** [4pts] Graphically show how the numbers on the decimal real line are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b95cccb5e3723bc4ebd7a1a10500f39a",
     "grade": true,
     "grade_id": "cell-4c6d3ae47566d1f1",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "d_1_values = [1]\n",
    "d_2_values = [0, 1, 2, 3]\n",
    "d_3_values = [0, 1, 2, 3]\n",
    "E_values = [-3, -2 , -1, 0, 1, 2, 3]\n",
    "\n",
    "fig = plt.figure(figsize=(10.0, 1.0))\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for E in E_values:\n",
    "    for d1 in d_1_values:\n",
    "        for d2 in d_2_values:\n",
    "            for d3 in d_3_values:\n",
    "                axes.plot( (d1 + d2 * 0.25 + d3*0.0625) * 2**E, 0.0, 'r+', markersize=20)\n",
    "                axes.plot(-(d1 + d2 * 0.25 + d3*0.0625) * 2**E, 0.0, 'r+', markersize=20)\n",
    "            \n",
    "axes.plot(0.0, 0.0, 'r+', markersize=20)\n",
    "axes.plot([-4.5, 4.5], [0.0, 0.0], 'k')\n",
    "\n",
    "axes.set_title(\"Distribution of Values\")\n",
    "axes.set_yticks([])\n",
    "axes.set_xticks(numpy.linspace(-4,4,9))\n",
    "axes.set_xlabel(\"x\")\n",
    "axes.set_ylabel(\"\")\n",
    "axes.grid()\n",
    "axes.set_xlim([-5, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fab0fc5f3065c300023b60719c30cb3b",
     "grade": false,
     "grade_id": "cell-93396552502746268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** [4 pts] How many more numbers can we store in $N$ base-pairs (base 4) versus $N$ bits (base 2) where the mantissa and exponent are the same relative length (e.g.  p=3, and $E\\in[-3,3]$ for both problems)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16825fa4b75b7fc34d854b1653fe64b8",
     "grade": true,
     "grade_id": "cell-6de5d8dbf91c5ff7",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$$ N(base = 4) = 2 \\times 3 \\times 4^{(p-1)} \\times E + 1 $$\n",
    "$$ N(base = 2) = 2 \\times 1 \\times 2^{(p-1)} \\times E + 1 $$\n",
    "$$ N(base = 4) - N(base = 2) = 2 \\times 3 \\times 4^{(p-1)} \\times E + 1 - 2 \\times 1 \\times 2^{(p-1)} \\times E - 1 $$\n",
    "$$ N(base = 4) - N(base = 2) = 2 \\times 3 \\times 4^{(p-1)} \\times E  - 2 \\times 1 \\times 2^{(p-1)} \\times E $$\n",
    "$$ N(base = 4) - N(base = 2) =  E \\times (2 \\times 3 \\times 4^{(p-1)}  - 2 \\times 1 \\times 2^{(p-1)}) $$\n",
    "$$ N(base = 4) - N(base = 2) = E \\times (2 \\times 3 \\times 4^{(p-1)}  - 2 \\times 1 \\times 2^{(p-1)}) $$\n",
    "$$ N(base = 4) - N(base = 2) = E \\times (2 \\times 3 \\times 2^{2(p-1)}  - 2 \\times 1 \\times 2^{(p-1)}) $$\n",
    "$$ N(base = 4) - N(base = 2) = E \\times (2 \\times 3 \\times 2^{2(p-1)}  - 2^{p}) $$\n",
    "$$ N(base = 4) - N(base = 2) = E \\times 2^{p}(3 \\times 2^{(p-1)}  - 1) $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
